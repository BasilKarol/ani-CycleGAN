{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Anime CycleGAN. Implementation by Vasili Karol**","metadata":{}},{"cell_type":"markdown","source":"# Chapter 1 - preparing data\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset, ConcatDataset\nfrom torch.autograd import Variable\n\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\n\nimport numpy as np\nfrom numpy.random import uniform as rand_noise\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport random\nfrom tqdm.notebook import tqdm\nimport glob, itertools\nfrom PIL import Image as PILImage\n\nsns.set(style='darkgrid', font_scale=1.2)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:18.545548Z","iopub.execute_input":"2022-02-06T23:12:18.546023Z","iopub.status.idle":"2022-02-06T23:12:20.789421Z","shell.execute_reply.started":"2022-02-06T23:12:18.545906Z","shell.execute_reply":"2022-02-06T23:12:20.788564Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"***All work has been done on kaggle platform. Links to Data and Net's weights:***\n\nhttps://www.kaggle.com/arnaud58/selfie2anime\n\nhttps://www.kaggle.com/shadowedtomb/anigan","metadata":{}},{"cell_type":"code","source":"Path = '../input/selfie2anime'","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:20.791381Z","iopub.execute_input":"2022-02-06T23:12:20.791646Z","iopub.status.idle":"2022-02-06T23:12:20.795396Z","shell.execute_reply.started":"2022-02-06T23:12:20.79161Z","shell.execute_reply":"2022-02-06T23:12:20.794681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#image_size = 256\nmean = (0.5, 0.5, 0.5)\nstd = (0.5, 0.5, 0.5)\ntransforms = tt.Compose( [\n                          #tt.Resize([image_size, image_size]),\n                          tt.ToTensor(),\n                          tt.Normalize(mean=mean, std=std)\n ] )","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:20.796801Z","iopub.execute_input":"2022-02-06T23:12:20.797341Z","iopub.status.idle":"2022-02-06T23:12:20.806409Z","shell.execute_reply.started":"2022-02-06T23:12:20.7973Z","shell.execute_reply":"2022-02-06T23:12:20.805743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**ImageDataset** inspiration from BALRAJ ASHWATH's work:\n\nhttps://www.kaggle.com/balraj98/cyclegan-translating-paintings-photos-pytorch","metadata":{}},{"cell_type":"code","source":"class ImageDataset(Dataset):\n    def __init__(self, root, transforms_=transforms, mode=\"train\"):\n        self.transform = transforms_\n\n        self.files_A = sorted(glob.glob(os.path.join(root, f\"{mode}A\") + \"/*.*\"))\n        self.files_B = sorted(glob.glob(os.path.join(root, f\"{mode}B\") + \"/*.*\"))\n\n    def __getitem__(self, index):\n        image_A = PILImage.open(self.files_A[index % len(self.files_A)])\n        image_B = PILImage.open(self.files_B[index % len(self.files_B)])\n            \n        # Convert grayscale images to rgb\n        if image_A.mode != \"RGB\":\n            image_A = to_rgb(image_A)\n        if image_B.mode != \"RGB\":\n            image_B = to_rgb(image_B)\n\n        item_A = self.transform(image_A)\n        item_B = self.transform(image_B)\n        return {\"A\": item_A, \"B\": item_B}\n\n    def __len__(self):\n        return max(len(self.files_A), len(self.files_B))","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:20.810124Z","iopub.execute_input":"2022-02-06T23:12:20.812173Z","iopub.status.idle":"2022-02-06T23:12:20.822337Z","shell.execute_reply.started":"2022-02-06T23:12:20.812139Z","shell.execute_reply":"2022-02-06T23:12:20.82167Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"TestData = DataLoader(ImageDataset(Path, mode='test'), num_workers=2, shuffle=True, pin_memory=True)   \nImgDataset = DataLoader(ImageDataset(Path), num_workers=2, shuffle=True, pin_memory=True)   ","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:20.824763Z","iopub.execute_input":"2022-02-06T23:12:20.826285Z","iopub.status.idle":"2022-02-06T23:12:22.060514Z","shell.execute_reply.started":"2022-02-06T23:12:20.826232Z","shell.execute_reply":"2022-02-06T23:12:22.059747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Id в Dataset'е: 0/2 - Monet test/train, 1/3- Photo test/train**","metadata":{}},{"cell_type":"code","source":"def show_grid(grid_images, grid_size, figsize=8):\n    fig, ax = plt.subplots(figsize=(figsize,figsize))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow( torch.moveaxis(make_grid(grid_images[:np.prod(grid_size)], nrow=grid_size[1], normalize=True ), 0, -1) )\n    plt.show()\n\nAnime_ex = []\nReal_ex = []\nfor img in ImgDataset:\n    Anime_ex.append(img['B'].view(3, 256, 256))\n    Real_ex.append(img['A'].view(3, 256, 256))\n    if len(Anime_ex)==8 and len(Real_ex)==8:\n        show_grid(Real_ex+Anime_ex, [2, 8], 15)\n        break\ndel Anime_ex\ndel Real_ex","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:22.061983Z","iopub.execute_input":"2022-02-06T23:12:22.062235Z","iopub.status.idle":"2022-02-06T23:12:25.457517Z","shell.execute_reply.started":"2022-02-06T23:12:22.062199Z","shell.execute_reply":"2022-02-06T23:12:25.456851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chapter 2 - building networks\n","metadata":{}},{"cell_type":"code","source":"device = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.458916Z","iopub.execute_input":"2022-02-06T23:12:25.459788Z","iopub.status.idle":"2022-02-06T23:12:25.463558Z","shell.execute_reply.started":"2022-02-06T23:12:25.459746Z","shell.execute_reply":"2022-02-06T23:12:25.462819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Nets implemented from official paper:\n\nhttps://arxiv.org/pdf/1703.10593.pdf","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.downsample = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True)\n            )\n        \n        self.res_block_sample = [\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1,bias=False),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1,bias=False),\n            nn.InstanceNorm2d(256)\n        ]\n        self.Res_block1 = nn.Sequential(*self.res_block_sample)\n        self.Res_block2 = nn.Sequential(*self.res_block_sample)\n        self.Res_block3 = nn.Sequential(*self.res_block_sample)\n        self.Res_block4 = nn.Sequential(*self.res_block_sample)\n        self.Res_block5 = nn.Sequential(*self.res_block_sample)\n        self.Res_block6 = nn.Sequential(*self.res_block_sample)\n        self.Res_block7 = nn.Sequential(*self.res_block_sample)\n        self.Res_block8 = nn.Sequential(*self.res_block_sample)\n        self.Res_block9 = nn.Sequential(*self.res_block_sample)\n        \n        self.upsample = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(64, 3, kernel_size=7, stride=1, padding=3, bias=False),\n            nn.Tanh()\n        )\n    def forward(self, x):\n        x = self.downsample(x)\n        \n        #9 times for 256*256, 6 times for 128*128\n        x = x + self.Res_block1(x)\n        x = x + self.Res_block2(x)\n        x = x + self.Res_block3(x)\n        x = x + self.Res_block4(x)\n        x = x + self.Res_block5(x)\n        x = x + self.Res_block6(x)\n        x = x + self.Res_block7(x)\n        x = x + self.Res_block8(x)\n        x = x + self.Res_block9(x)\n        \n        x = self.upsample(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.464766Z","iopub.execute_input":"2022-02-06T23:12:25.465499Z","iopub.status.idle":"2022-02-06T23:12:25.485939Z","shell.execute_reply.started":"2022-02-06T23:12:25.46546Z","shell.execute_reply":"2022-02-06T23:12:25.485182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Generator_x = Generator().to(device)\nGenerator_z = Generator().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.487017Z","iopub.execute_input":"2022-02-06T23:12:25.487463Z","iopub.status.idle":"2022-02-06T23:12:25.541721Z","shell.execute_reply.started":"2022-02-06T23:12:25.487427Z","shell.execute_reply":"2022-02-06T23:12:25.541109Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"GaussianNoise code from  \n\nhttps://github.com/ShivamShrirao/facegan_pytorch/blob/main/facegan_pytorch.ipynb\n","metadata":{}},{"cell_type":"code","source":"class GaussianNoise(nn.Module):                 \n    def __init__(self, std=0.1, decay_rate=0):\n        super().__init__()\n        self.std = std\n        self.decay_rate = decay_rate\n\n    def decay_step(self):\n        self.std = max(self.std - self.decay_rate, 0)\n\n    def forward(self, x):\n        if self.training:\n            return x + torch.empty_like(x).normal_(std=self.std)\n        else:\n            return x","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.544388Z","iopub.execute_input":"2022-02-06T23:12:25.544691Z","iopub.status.idle":"2022-02-06T23:12:25.55051Z","shell.execute_reply.started":"2022-02-06T23:12:25.544656Z","shell.execute_reply":"2022-02-06T23:12:25.549641Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#70*70 PatchGAN architecture\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.downsample = nn.Sequential(\n            GaussianNoise(),\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            GaussianNoise(),\n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            GaussianNoise(),\n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            GaussianNoise(),\n            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            GaussianNoise(),\n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1,bias=False),\n            #nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        return self.downsample(x) ","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.551731Z","iopub.execute_input":"2022-02-06T23:12:25.552206Z","iopub.status.idle":"2022-02-06T23:12:25.562855Z","shell.execute_reply.started":"2022-02-06T23:12:25.552171Z","shell.execute_reply":"2022-02-06T23:12:25.562148Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Discriminator_x = Discriminator().to(device)\nDiscriminator_z = Discriminator().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.564136Z","iopub.execute_input":"2022-02-06T23:12:25.564396Z","iopub.status.idle":"2022-02-06T23:12:25.618895Z","shell.execute_reply.started":"2022-02-06T23:12:25.564363Z","shell.execute_reply":"2022-02-06T23:12:25.618298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Function and idea of **weights_init** from official pytorch implementation:\n\nhttps://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html","metadata":{}},{"cell_type":"code","source":"def weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n        \n#normalize weights:\nGenerator_x.apply(weights_init)   \nGenerator_z.apply(weights_init)   \nDiscriminator_x.apply(weights_init)\nDiscriminator_z.apply(weights_init)","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.620033Z","iopub.execute_input":"2022-02-06T23:12:25.620285Z","iopub.status.idle":"2022-02-06T23:12:25.632435Z","shell.execute_reply.started":"2022-02-06T23:12:25.620238Z","shell.execute_reply":"2022-02-06T23:12:25.631742Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Adversarial = nn.MSELoss().cuda()\nConsistency = nn.L1Loss().cuda()\nIdentify = nn.L1Loss().cuda()\n\ncriterion = {\n    #*0.5 for discriminators\n    'Adversarial' : Adversarial, #D(real/fake) and 1/0\n    \n    #*10 for Consistency\n    'Consistency' : Consistency, #G_z(G_x(x)) and x\n    \n    'Identify' : Identify #G_x(x) and z\n}","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.633635Z","iopub.execute_input":"2022-02-06T23:12:25.633888Z","iopub.status.idle":"2022-02-06T23:12:25.638787Z","shell.execute_reply.started":"2022-02-06T23:12:25.633854Z","shell.execute_reply":"2022-02-06T23:12:25.637919Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = 1e-04\noptims = {\n    'generator_x' : torch.optim.Adam(Generator_x.parameters(), lr=lr, betas=(0.5, 0.999)),\n    'generator_z' : torch.optim.Adam(Generator_z.parameters(), lr=lr, betas=(0.5, 0.999)),\n    \n    'discriminator_x' : torch.optim.Adam(Discriminator_x.parameters(), lr=lr, betas=(0.5, 0.999)),\n    'discriminator_z' : torch.optim.Adam(Discriminator_z.parameters(), lr=lr, betas=(0.5, 0.999))\n}\n\nscheduler = {\n    \"discriminator_x\": lr_scheduler.StepLR(optims['discriminator_x'], step_size=5, gamma=0.5),\n    \"discriminator_z\": lr_scheduler.StepLR(optims['discriminator_z'], step_size=5, gamma=0.5),\n    \"generator_x\": lr_scheduler.StepLR(optims['generator_x'], step_size=5, gamma=0.5),\n    \"generator_z\": lr_scheduler.StepLR(optims['generator_z'], step_size=5, gamma=0.5)\n} ","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.640153Z","iopub.execute_input":"2022-02-06T23:12:25.640689Z","iopub.status.idle":"2022-02-06T23:12:25.650354Z","shell.execute_reply.started":"2022-02-06T23:12:25.640653Z","shell.execute_reply":"2022-02-06T23:12:25.649504Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chapter 3 - train loop\n","metadata":{}},{"cell_type":"code","source":"Epochs = 200\nConsistency_a = 10\nhistory = {'gx':[],\n           'gz':[],\n           'dx':[],\n           'dz':[]\n          }","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:25.651183Z","iopub.execute_input":"2022-02-06T23:12:25.651387Z","iopub.status.idle":"2022-02-06T23:12:25.662072Z","shell.execute_reply.started":"2022-02-06T23:12:25.651363Z","shell.execute_reply":"2022-02-06T23:12:25.661313Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_load = './AnimeGAN+_100_params'\nLOAD = True\n\nif LOAD == True:\n    checkpoint = torch.load(PATH_load)\n    Discriminator_z.load_state_dict(checkpoint['dz'])\n    Generator_z.load_state_dict(checkpoint['gz'])\n    Discriminator_x.load_state_dict(checkpoint['dx'])\n    Generator_x.load_state_dict(checkpoint['gx'])\n    \n    optims['generator_x'].load_state_dict(checkpoint['optim_gx'])\n    optims['generator_z'].load_state_dict(checkpoint['optim_gz'])\n    optims['discriminator_x'].load_state_dict(checkpoint['optim_dx'])\n    optims['discriminator_z'].load_state_dict(checkpoint['optim_dz'])","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:52:42.159371Z","iopub.execute_input":"2022-02-07T07:52:42.159987Z","iopub.status.idle":"2022-02-07T07:52:42.235672Z","shell.execute_reply.started":"2022-02-07T07:52:42.159945Z","shell.execute_reply":"2022-02-07T07:52:42.234946Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tensor = torch.cuda.FloatTensor ","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:28.140734Z","iopub.execute_input":"2022-02-06T23:12:28.140945Z","iopub.status.idle":"2022-02-06T23:12:28.147209Z","shell.execute_reply.started":"2022-02-06T23:12:28.140919Z","shell.execute_reply":"2022-02-06T23:12:28.146501Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER = True\nif BUFFER:\n    Buffer_x = [] \n    Buffer_z = [] ","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:28.150572Z","iopub.execute_input":"2022-02-06T23:12:28.150996Z","iopub.status.idle":"2022-02-06T23:12:28.155165Z","shell.execute_reply.started":"2022-02-06T23:12:28.150965Z","shell.execute_reply":"2022-02-06T23:12:28.154506Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Output mechanism** was made within information from tqdm issue:\n\nhttps://github.com/tqdm/tqdm/issues/818","metadata":{}},{"cell_type":"code","source":"#training\nfrom IPython import display\nfrom ipywidgets import Output\nfrom numpy.random import uniform as rand_noise\nout = Output()\ndisplay.display(out)\n\nDiscriminator_x.train()\nDiscriminator_z.train()\nGenerator_x.train()\nGenerator_z.train()\n\nfor epoch in tqdm(range(1, Epochs+1)):\n    \n    if epoch > 100:\n        scheduler['generator_x'].step()\n        scheduler['generator_z'].step()\n        scheduler['discriminator_x'].step()\n        scheduler['discriminator_z'].step()\n    \n    history_per_epoch = {'gx':[], 'gz':[], 'dx':[], 'dz':[]}\n    \n    for Image in ImgDataset:\n        Anime = Variable(Image['B'].type(Tensor))        \n        Real = Variable(Image['A'].type(Tensor))        \n           ##  Real images  ##\n        #Adversarial\n        optims['generator_x'].zero_grad()\n        Z_fake = Generator_x(Real)  \n        if len(Buffer_x) < 50:\n            Buffer_x.append(Z_fake)\n        Buffer_id = random.randint(0, len(Buffer_x)-1)\n        Z_fake_label = Discriminator_x(Z_fake)\n        Zeros = Variable(Tensor(np.zeros(Z_fake_label.size())), requires_grad=False)\n        Ones = Variable(Tensor(np.ones(Z_fake_label.size())), requires_grad=False)\n        gx_loss = criterion['Adversarial']( Z_fake_label, Ones )\n        gx_loss.backward()\n        optims['generator_x'].step()\n        \n        #Consistency\n        optims['generator_x'].zero_grad()\n        optims['generator_z'].zero_grad()\n        Regen = Generator_z( Generator_x(Real))\n        cons_loss = Consistency_a*criterion['Consistency']( Regen, Real)\n        cons_loss.backward()\n        optims['generator_x'].step()\n        optims['generator_z'].step()\n        \n        #Identify\n        optims['generator_x'].zero_grad()\n        ident_loss = criterion['Identify']( Generator_x(Real), Real)\n        ident_loss.backward()\n        optims['generator_x'].step()\n        \n        optims['discriminator_x'].zero_grad()\n        Fake_ = Buffer_x[Buffer_id]\n        dx_loss = criterion['Adversarial'](Discriminator_x(Fake_.detach()), Zeros + rand_noise(0, 0.3))\n        Buffer_x[Buffer_id] = Z_fake\n        #del Fake_\n        dx_loss.backward()\n        optims['discriminator_x'].step()\n        \n        optims['discriminator_z'].zero_grad()\n        dz_loss = criterion['Adversarial'](Discriminator_z(Real), Ones+ rand_noise(-0.2, 0.2) )\n        dz_loss.backward()\n        optims['discriminator_z'].step()\n        \n        history_per_epoch['gx'].append(gx_loss.item())\n        history_per_epoch['dx'].append(dx_loss.item())\n        history_per_epoch['dz'].append(dz_loss.item())\n            \n            \n               ##  Anime images  ##\n        optims['generator_z'].zero_grad()\n        X_fake = Generator_z(Anime)\n        if len(Buffer_z) < 50:\n            Buffer_z.append(X_fake)\n        Buffer_id = random.randint(0, len(Buffer_z)-1)\n        X_fake_label = Discriminator_z(X_fake)\n        Zeros = Variable(Tensor(np.zeros(X_fake_label.size())), requires_grad=False)\n        Ones = Variable(Tensor(np.ones(X_fake_label.size())), requires_grad=False)\n        gz_loss = criterion['Adversarial']( X_fake_label, Ones )\n        gz_loss.backward()\n        optims['generator_z'].step()\n        \n        #Consistency\n        optims['generator_z'].zero_grad()\n        optims['generator_x'].zero_grad()\n        Regen = Generator_x( Generator_z(Anime))\n        cons_loss = Consistency_a*criterion['Consistency']( Regen , Anime)\n        cons_loss.backward()\n        optims['generator_z'].step()\n        optims['generator_x'].step()\n        \n        #Identify\n        optims['generator_z'].zero_grad()\n        ident_loss = criterion['Identify']( Generator_z(Anime), Anime)\n        ident_loss.backward()\n        optims['generator_z'].step()\n        \n        optims['discriminator_x'].zero_grad()\n        dx_loss = criterion['Adversarial'](Discriminator_x(Anime), Ones+ rand_noise(-0.2, 0.2))\n        dx_loss.backward()\n        optims['discriminator_x'].step()\n        \n        optims['discriminator_z'].zero_grad()\n        Fake_ = Buffer_z[Buffer_id]\n        dz_loss = criterion['Adversarial'](Discriminator_z(Fake_.detach()), Zeros+ rand_noise(0, 0.3))\n        Buffer_z[Buffer_id] = X_fake\n        dz_loss.backward()\n        optims['discriminator_z'].step()\n        \n        history_per_epoch['gz'].append(gz_loss.item())\n        history_per_epoch['dx'].append(dx_loss.item())\n        history_per_epoch['dz'].append(dz_loss.item())\n            \n    history['gx'].append(np.mean(history_per_epoch['gx']))\n    history['gz'].append(np.mean(history_per_epoch['gz']))\n    history['dx'].append(np.mean(history_per_epoch['dx']))\n    history['dz'].append(np.mean(history_per_epoch['dz']))\n    \n    with torch.set_grad_enabled(False):\n      with out:\n        display.clear_output(wait=True)\n        print(f\"\"\"Epoch: {epoch}/{Epochs}  Discr Loss: {history['dx'][-1]},{history['dz'][-1]}   \n              Gen Loss: {history['gx'][-1]}, {history['gz'][-1]} \\n Monet2Photo \\t\\t\\t\\t Photo2Monet\"\"\")\n        for Image_test in ImgDataset:\n            Z_fake = Generator_x.forward(Image_test['A'].cuda())\n            X_fake = Generator_z.forward(Image_test['B'].cuda())\n            break\n        show_grid([Z_fake.view(3,256,256).cpu(), X_fake.view(3,256,256).cpu()], [1, 2])      \n        del Z_fake\n        del X_fake","metadata":{"execution":{"iopub.status.busy":"2022-02-06T23:12:28.156637Z","iopub.execute_input":"2022-02-06T23:12:28.157257Z","iopub.status.idle":"2022-02-07T07:46:46.141865Z","shell.execute_reply.started":"2022-02-06T23:12:28.157222Z","shell.execute_reply":"2022-02-07T07:46:46.140535Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chapter 4 - result's analysis and saving model's parameters\n","metadata":{}},{"cell_type":"code","source":"figure = plt.figure(figsize=(12, 7))\nplt.plot(history['dx'], label='Discriminator_x')\nplt.plot(history['gx'], label='Generator_x')\nplt.plot(history['dz'], label='Discriminator_z')\nplt.plot(history['gz'], label='Generator_z')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:46:53.749895Z","iopub.execute_input":"2022-02-07T07:46:53.750155Z","iopub.status.idle":"2022-02-07T07:46:54.003968Z","shell.execute_reply.started":"2022-02-07T07:46:53.750124Z","shell.execute_reply":"2022-02-07T07:46:54.003315Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"PATH_save = 'AnimeGAN+_100_params'\n\ntorch.save({\n    'dx' : Discriminator_x.state_dict(),\n    'dz' : Discriminator_z.state_dict(),\n    'gx' : Generator_x.state_dict(),\n    'gz' : Generator_z.state_dict(),\n    \n    'optim_gx': optims['generator_x'].state_dict(),\n    'optim_gz': optims['generator_z'].state_dict(),\n    'optim_dx': optims['discriminator_x'].state_dict(),\n    'optim_dz': optims['discriminator_z'].state_dict(),\n            }, PATH_save)\n","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:47:02.338463Z","iopub.execute_input":"2022-02-07T07:47:02.339153Z","iopub.status.idle":"2022-02-07T07:47:02.511137Z","shell.execute_reply.started":"2022-02-07T07:47:02.339113Z","shell.execute_reply":"2022-02-07T07:47:02.510247Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href='AnimeGAN_30_params'> AnimeGAN_30_params </a>","metadata":{}},{"cell_type":"code","source":"PATH_load = '../input/anigan/AnimeGAN_70_params'\ncheckpoint = torch.load(PATH_load)\nGenerator_old_x = Generator().to(device)\nGenerator_old_z = Generator().to(device)\n\nGenerator_old_z.load_state_dict(checkpoint['gz'])\nGenerator_old_x.load_state_dict(checkpoint['gx'])\n    ","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:56:53.140139Z","iopub.execute_input":"2022-02-07T07:56:53.140942Z","iopub.status.idle":"2022-02-07T07:56:53.260771Z","shell.execute_reply.started":"2022-02-07T07:56:53.140897Z","shell.execute_reply":"2022-02-07T07:56:53.260027Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_samples = 6\nReal = []\nFakes = []\nOld_Fakes = []\nGenerator_x.eval()\nGenerator_old_x.eval()\nfor img in TestData:\n    with torch.set_grad_enabled(False):\n        Real.append(img['B'].view(3, 256, 256))\n        Old_Fakes.append(Generator_old_z(img['B'].cuda()).view( 3, 256, 256).cpu())\n        Fakes.append(Generator_z(img['B'].cuda()).view( 3, 256, 256).cpu())\n    n_samples -=1\n    if n_samples <= 0:\n        break\nshow_grid(Real+Old_Fakes+Fakes, [3, 6], 18)            \n\n\n        ","metadata":{"execution":{"iopub.status.busy":"2022-02-07T07:59:52.926477Z","iopub.execute_input":"2022-02-07T07:59:52.927222Z","iopub.status.idle":"2022-02-07T07:59:54.044357Z","shell.execute_reply.started":"2022-02-07T07:59:52.927171Z","shell.execute_reply":"2022-02-07T07:59:54.039176Z"},"trusted":true},"execution_count":null,"outputs":[]}]}