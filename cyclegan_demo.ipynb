{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# **Monet2Photo CycleGAN. Demo Implementation by Vasili Karol**","metadata":{}},{"cell_type":"markdown","source":"# Chapter 1 - preparing data\n","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader\nfrom torch.autograd import Variable\n\nfrom torchvision.utils import make_grid\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\n\nimport numpy as np\nfrom numpy.random import uniform as rand_noise\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport random\nfrom tqdm.notebook import tqdm\n\nsns.set(style='darkgrid', font_scale=1.2)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:16:56.185633Z","iopub.execute_input":"2022-01-30T10:16:56.186024Z","iopub.status.idle":"2022-01-30T10:16:58.576198Z","shell.execute_reply.started":"2022-01-30T10:16:56.18598Z","shell.execute_reply":"2022-01-30T10:16:58.575444Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Path = '../input/monet2photo'","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:16:58.579608Z","iopub.execute_input":"2022-01-30T10:16:58.579832Z","iopub.status.idle":"2022-01-30T10:16:58.583804Z","shell.execute_reply.started":"2022-01-30T10:16:58.579803Z","shell.execute_reply":"2022-01-30T10:16:58.583104Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"image_size = 256\nmean = (0.5, 0.5, 0.5)\nstd = (0.5, 0.5, 0.5)\ntransforms = tt.Compose( [\n                          tt.Resize([image_size, image_size]),\n                          tt.ToTensor(),\n                          tt.Normalize(mean=mean, std=std)\n ] )\n\nimages = ImageFolder(Path, transform=transforms )","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:16:58.586183Z","iopub.execute_input":"2022-01-30T10:16:58.586698Z","iopub.status.idle":"2022-01-30T10:17:03.820855Z","shell.execute_reply.started":"2022-01-30T10:16:58.586657Z","shell.execute_reply":"2022-01-30T10:17:03.820059Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Id в Dataset'е: 0/2 - Monet test/train, 1/3- Photo test/train**","metadata":{}},{"cell_type":"code","source":"Dataset = DataLoader(images, num_workers=2, shuffle=True, pin_memory=True)   ","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:17:03.823043Z","iopub.execute_input":"2022-01-30T10:17:03.823465Z","iopub.status.idle":"2022-01-30T10:17:03.827947Z","shell.execute_reply.started":"2022-01-30T10:17:03.823427Z","shell.execute_reply":"2022-01-30T10:17:03.827271Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Балансировка Photo и Monet в меньшую сторону\ndef custom_count(list, x, dim=None):\n    n = 0\n    if dim:\n        for a in list:\n            if a[dim] == x:\n                n += 1\n    else:\n        for a in list:\n            if a == x or x in a:\n                n += 1\n    return n\n\nMonet_len = custom_count(Dataset.dataset, 2, dim=1)\nPhoto_len = custom_count(Dataset.dataset, 3, dim=1)    \nlimit = 0\nwhile limit < (Photo_len-Monet_len):\n    for x in Dataset.dataset.imgs:\n        if x[1] == 3 and limit < (Photo_len-Monet_len):\n            Dataset.dataset.imgs.remove(x)\n            limit += 1","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:17:03.830076Z","iopub.execute_input":"2022-01-30T10:17:03.830541Z","iopub.status.idle":"2022-01-30T10:18:22.162232Z","shell.execute_reply.started":"2022-01-30T10:17:03.830505Z","shell.execute_reply":"2022-01-30T10:18:22.161451Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Dataset.dataset","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:18:22.163471Z","iopub.execute_input":"2022-01-30T10:18:22.163745Z","iopub.status.idle":"2022-01-30T10:18:22.173209Z","shell.execute_reply.started":"2022-01-30T10:18:22.163706Z","shell.execute_reply":"2022-01-30T10:18:22.172204Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Test_monet = []\nTest_photo = []\nlimit_test = 0\n\nfor x in Dataset.dataset:\n    if x[1] == 0: \n        Test_monet.append(x[0])\n    elif x[1] == 1:\n        Test_photo.append(x[0])\n        \nwhile limit_test < (751+121):\n    for x in Dataset.dataset.imgs:\n        if x[1] == 0: \n            Dataset.dataset.imgs.remove(x)\n            limit_test += 1\n        elif x[1] == 1:\n            Dataset.dataset.imgs.remove(x)\n            limit_test += 1\n\nTest_monet = DataLoader(Test_monet, num_workers=2, shuffle=True, pin_memory=True)   \nTest_photo = DataLoader(Test_photo, num_workers=2, shuffle=True, pin_memory=True)   ","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:18:22.175001Z","iopub.execute_input":"2022-01-30T10:18:22.175503Z","iopub.status.idle":"2022-01-30T10:18:30.450667Z","shell.execute_reply.started":"2022-01-30T10:18:22.175464Z","shell.execute_reply":"2022-01-30T10:18:30.449886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_grid(grid_images, grid_size, figsize=8):\n    fig, ax = plt.subplots(figsize=(figsize,figsize))\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.imshow( torch.moveaxis(make_grid(grid_images[:np.prod(grid_size)], nrow=grid_size[1], normalize=True ), 0, -1) )\n    plt.show()\n\na = [1, 1]\nlist_demonstration = [[], []]\nfor Image, id in Dataset:\n    if id ==2 and len(list_demonstration[0])<8:\n        list_demonstration[0].append(Image.reshape(Image.size()[1:]))\n        a[0] += 1\n    if id ==3 and len(list_demonstration[1])<8:\n        list_demonstration[1].append(Image.reshape(Image.size()[1:]))\n        a[1] += 1\n    if a[0] > 8 and a[1] > 8:\n        show_grid(list_demonstration[0] + list_demonstration[1], [2, 8], 20)\n        break\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:18:30.451887Z","iopub.execute_input":"2022-01-30T10:18:30.452154Z","iopub.status.idle":"2022-01-30T10:18:34.044257Z","shell.execute_reply.started":"2022-01-30T10:18:30.452121Z","shell.execute_reply":"2022-01-30T10:18:34.043572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:18:34.047107Z","iopub.execute_input":"2022-01-30T10:18:34.047673Z","iopub.status.idle":"2022-01-30T10:18:34.055352Z","shell.execute_reply.started":"2022-01-30T10:18:34.04764Z","shell.execute_reply":"2022-01-30T10:18:34.054645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chapter 2 - building networks","metadata":{}},{"cell_type":"code","source":"class Generator(nn.Module):\n    def __init__(self):\n        super(Generator, self).__init__()\n        self.downsample = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=7, stride=1, padding=3,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            \n            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True)\n            )\n        \n        self.res_block_sample = [\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1,bias=False),\n            nn.InstanceNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1,bias=False),\n            nn.InstanceNorm2d(256)\n        ]\n        self.Res_block1 = nn.Sequential(*self.res_block_sample)\n        self.Res_block2 = nn.Sequential(*self.res_block_sample)\n        self.Res_block3 = nn.Sequential(*self.res_block_sample)\n        self.Res_block4 = nn.Sequential(*self.res_block_sample)\n        self.Res_block5 = nn.Sequential(*self.res_block_sample)\n        self.Res_block6 = nn.Sequential(*self.res_block_sample)\n        self.Res_block7 = nn.Sequential(*self.res_block_sample)\n        self.Res_block8 = nn.Sequential(*self.res_block_sample)\n        self.Res_block9 = nn.Sequential(*self.res_block_sample)\n        \n        self.upsample = nn.Sequential(\n            nn.ConvTranspose2d(256, 128, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.InstanceNorm2d(128),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(128, 64, kernel_size=3, stride=2, padding=1, output_padding=1, bias=False),\n            nn.InstanceNorm2d(64),\n            nn.ReLU(inplace=True),\n            \n            nn.ConvTranspose2d(64, 3, kernel_size=7, stride=1, padding=3, bias=False),\n            nn.Tanh()\n        )\n    def forward(self, x):\n        x = self.downsample(x)\n        \n        #9 times for 256*256, 6 times for 128*128\n        x = x + self.Res_block1(x)\n        x = x + self.Res_block2(x)\n        x = x + self.Res_block3(x)\n        x = x + self.Res_block4(x)\n        x = x + self.Res_block5(x)\n        x = x + self.Res_block6(x)\n        x = x + self.Res_block7(x)\n        x = x + self.Res_block8(x)\n        x = x + self.Res_block9(x)\n        \n        x = self.upsample(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:48.777122Z","iopub.execute_input":"2022-01-30T10:28:48.777489Z","iopub.status.idle":"2022-01-30T10:28:48.796438Z","shell.execute_reply.started":"2022-01-30T10:28:48.777453Z","shell.execute_reply":"2022-01-30T10:28:48.795789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Generator_x = Generator().to(device)\nGenerator_z = Generator().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:49.594729Z","iopub.execute_input":"2022-01-30T10:28:49.594989Z","iopub.status.idle":"2022-01-30T10:28:49.643094Z","shell.execute_reply.started":"2022-01-30T10:28:49.59496Z","shell.execute_reply":"2022-01-30T10:28:49.642363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#70*70 PatchGAN architecture\nclass Discriminator(nn.Module):\n    def __init__(self):\n        super(Discriminator, self).__init__()\n        self.downsample = nn.Sequential(\n            nn.Conv2d(3, 64, kernel_size=4, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=1,bias=False),\n            nn.InstanceNorm2d(64),\n            nn.LeakyReLU(0.2, inplace=True),\n            \n            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=1,bias=False),\n            #nn.Sigmoid()\n        )\n        \n    def forward(self, x):\n        return self.downsample(x) ","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:50.435155Z","iopub.execute_input":"2022-01-30T10:28:50.435707Z","iopub.status.idle":"2022-01-30T10:28:50.445178Z","shell.execute_reply.started":"2022-01-30T10:28:50.435668Z","shell.execute_reply":"2022-01-30T10:28:50.444509Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Discriminator_x = Discriminator().to(device)\nDiscriminator_z = Discriminator().to(device)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:50.702557Z","iopub.execute_input":"2022-01-30T10:28:50.70276Z","iopub.status.idle":"2022-01-30T10:28:50.754678Z","shell.execute_reply.started":"2022-01-30T10:28:50.702736Z","shell.execute_reply":"2022-01-30T10:28:50.754037Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#function and idea from https://pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html\ndef weights_init(m):\n    classname = m.__class__.__name__\n    if classname.find('Conv') != -1:\n        nn.init.normal_(m.weight.data, 0.0, 0.02)\n        \n#normalize weights:\nGenerator_x.apply(weights_init)   \nGenerator_z.apply(weights_init)   \nDiscriminator_x.apply(weights_init)\nDiscriminator_z.apply(weights_init)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:50.965836Z","iopub.execute_input":"2022-01-30T10:28:50.966091Z","iopub.status.idle":"2022-01-30T10:28:50.977761Z","shell.execute_reply.started":"2022-01-30T10:28:50.966061Z","shell.execute_reply":"2022-01-30T10:28:50.976978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Adversarial = nn.MSELoss().cuda()\nConsistency = nn.L1Loss().cuda()\nIdentify = nn.L1Loss().cuda()\n\ncriterion = {\n    #*0.5 for discriminators\n    'Adversarial' : Adversarial, #D(real/fake) and 1/0\n    \n    #*10 for Consistency\n    'Consistency' : Consistency, #G_z(G_x(x)) and x\n    \n    'Identify' : Identify #G_x(x) and z\n}","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:52.611658Z","iopub.execute_input":"2022-01-30T10:28:52.612193Z","iopub.status.idle":"2022-01-30T10:28:52.61692Z","shell.execute_reply.started":"2022-01-30T10:28:52.612154Z","shell.execute_reply":"2022-01-30T10:28:52.616201Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"optims = {\n    'generator_x' : torch.optim.Adam(Generator_x.parameters(), lr=0.0002, betas=(0.5, 0.999)),\n    'generator_z' : torch.optim.Adam(Generator_z.parameters(), lr=0.0002, betas=(0.5, 0.999)),\n    \n    'discriminator_x' : torch.optim.Adam(Discriminator_x.parameters(), lr=0.0002, betas=(0.5, 0.999)),\n    'discriminator_z' : torch.optim.Adam(Discriminator_z.parameters(), lr=0.0002, betas=(0.5, 0.999))\n}\n\nscheduler = {\n    \"discriminator_x\": lr_scheduler.StepLR(optims['discriminator_x'], step_size=10, gamma=0.8),\n    \"discriminator_z\": lr_scheduler.StepLR(optims['discriminator_z'], step_size=10, gamma=0.8),\n    \"generator_x\": lr_scheduler.StepLR(optims['generator_x'], step_size=10, gamma=0.8),\n    \"generator_z\": lr_scheduler.StepLR(optims['generator_z'], step_size=10, gamma=0.8)\n} ","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:53.596795Z","iopub.execute_input":"2022-01-30T10:28:53.597471Z","iopub.status.idle":"2022-01-30T10:28:53.60892Z","shell.execute_reply.started":"2022-01-30T10:28:53.597431Z","shell.execute_reply":"2022-01-30T10:28:53.608152Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chapter 3 - train loop","metadata":{}},{"cell_type":"code","source":"Epochs = 100\nConsistency_a = 10\nhistory = {'gx':[],\n           'gz':[],\n           'dx':[],\n           'dz':[]\n          }","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:54.142522Z","iopub.execute_input":"2022-01-30T10:28:54.14279Z","iopub.status.idle":"2022-01-30T10:28:54.14702Z","shell.execute_reply.started":"2022-01-30T10:28:54.142759Z","shell.execute_reply":"2022-01-30T10:28:54.146298Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pretrained\nPathdx = '../input/cyclegan-weights/CycleGAN_50_dx'\nPathgx = '../input/cyclegan-weights/CycleGAN_50_gx'\nPathdz = '../input/cyclegan-weights/CycleGAN_50_dz'\nPathgz = '../input/cyclegan-weights/CycleGAN_50_gz'\nLOAD = False\n\nif LOAD == True:\n    Discriminator_z.load_state_dict(torch.load(Pathdz))\n    Generator_z.load_state_dict(torch.load(Pathgz))\n    Discriminator_x.load_state_dict(torch.load(Pathdx))\n    Generator_x.load_state_dict(torch.load(Pathgx))","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:56.086872Z","iopub.execute_input":"2022-01-30T10:28:56.087201Z","iopub.status.idle":"2022-01-30T10:28:56.097362Z","shell.execute_reply.started":"2022-01-30T10:28:56.087164Z","shell.execute_reply":"2022-01-30T10:28:56.096426Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Tensor = torch.cuda.FloatTensor ","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:56.641759Z","iopub.execute_input":"2022-01-30T10:28:56.642005Z","iopub.status.idle":"2022-01-30T10:28:56.646694Z","shell.execute_reply.started":"2022-01-30T10:28:56.641976Z","shell.execute_reply":"2022-01-30T10:28:56.644689Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BUFFER = True\nif BUFFER:\n    Buffer_x = [] #make_buffer(Generator_x, 2)\n    Buffer_z = [] #make_buffer(Generator_z, 3)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:28:57.386054Z","iopub.execute_input":"2022-01-30T10:28:57.38681Z","iopub.status.idle":"2022-01-30T10:28:57.402741Z","shell.execute_reply.started":"2022-01-30T10:28:57.386771Z","shell.execute_reply":"2022-01-30T10:28:57.402021Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#training\n#Это из stack overflow\nfrom IPython import display\nfrom ipywidgets import Output\nfrom numpy.random import uniform as rand_noise\nout = Output()\ndisplay.display(out)\n\nDiscriminator_x.train()\nDiscriminator_z.train()\nGenerator_x.train()\nGenerator_z.train()\n\nfor epoch in tqdm(range(1, Epochs+1)):\n    history_per_epoch = {'gx':[], 'gz':[], 'dx':[], 'dz':[]}\n    \n    for Image, Id in Dataset:\n        Image = Variable(Image.type(Tensor))\n        if Id == 2:\n            #Monet paintings\n            #Adversarial\n            optims['generator_x'].zero_grad()\n            Z_fake = Generator_x(Image)  \n            if len(Buffer_x) < 50:\n                Buffer_x.append(Z_fake)\n            Buffer_id = random.randint(0, len(Buffer_x)-1)\n            Z_fake_label = Discriminator_x(Z_fake)\n            Zeros = Variable(Tensor(np.zeros(Z_fake_label.size())), requires_grad=False)\n            Ones = Variable(Tensor(np.ones(Z_fake_label.size())), requires_grad=False)\n            gx_loss = criterion['Adversarial']( Z_fake_label, Ones )\n            gx_loss.backward()\n            optims['generator_x'].step()\n            \n            #Consistency\n            optims['generator_x'].zero_grad()\n            optims['generator_z'].zero_grad()\n            Regen = Generator_z( Generator_x(Image))\n            cons_loss = Consistency_a*criterion['Consistency']( Regen, Image)\n            cons_loss.backward()\n            optims['generator_x'].step()\n            optims['generator_z'].step()\n            \n            #Identify\n            optims['generator_x'].zero_grad()\n            ident_loss = criterion['Identify']( Generator_x(Image), Image)\n            ident_loss.backward()\n            optims['generator_x'].step()\n            \n            optims['discriminator_x'].zero_grad()\n            Fake_ = Buffer_x[Buffer_id]\n            dx_loss = criterion['Adversarial'](Discriminator_x(Fake_.detach()), Zeros + rand_noise(0, 0.3))\n            Buffer_x[Buffer_id] = Z_fake\n            #del Fake_\n            dx_loss.backward()\n            optims['discriminator_x'].step()\n            \n            optims['discriminator_z'].zero_grad()\n            dz_loss = criterion['Adversarial'](Discriminator_z(Image), Ones+ rand_noise(-0.2, 0.2) )\n            dz_loss.backward()\n            optims['discriminator_z'].step()\n            \n            history_per_epoch['gx'].append(gx_loss.item())\n            history_per_epoch['dx'].append(dx_loss.item())\n            history_per_epoch['dz'].append(dz_loss.item())\n\n        elif Id == 3:\n            #Real photoes\n            optims['generator_z'].zero_grad()\n            X_fake = Generator_z(Image)\n            if len(Buffer_z) < 50:\n                Buffer_z.append(X_fake)\n            Buffer_id = random.randint(0, len(Buffer_z)-1)\n            X_fake_label = Discriminator_z(X_fake)\n            Zeros = Variable(Tensor(np.zeros(X_fake_label.size())), requires_grad=False)\n            Ones = Variable(Tensor(np.ones(X_fake_label.size())), requires_grad=False)\n            gz_loss = criterion['Adversarial']( X_fake_label, Ones )\n            gz_loss.backward()\n            optims['generator_z'].step()\n            \n            #Consistency\n            optims['generator_z'].zero_grad()\n            optims['generator_x'].zero_grad()\n            Regen = Generator_x( Generator_z(Image))\n            cons_loss = Consistency_a*criterion['Consistency']( Regen , Image)\n            cons_loss.backward()\n            optims['generator_z'].step()\n            optims['generator_x'].step()\n            \n            #Identify\n            optims['generator_z'].zero_grad()\n            ident_loss = criterion['Identify']( Generator_z(Image), Image)\n            ident_loss.backward()\n            optims['generator_z'].step()\n            \n            optims['discriminator_x'].zero_grad()\n            dx_loss = criterion['Adversarial'](Discriminator_x(Image), Ones+ rand_noise(-0.2, 0.2))\n            dx_loss.backward()\n            optims['discriminator_x'].step()\n            \n            optims['discriminator_z'].zero_grad()\n            Fake_ = Buffer_z[Buffer_id]\n            dz_loss = criterion['Adversarial'](Discriminator_z(Fake_.detach()), Zeros+ rand_noise(0, 0.3))\n            Buffer_z[Buffer_id] = X_fake\n            #del Fake_\n            dz_loss.backward()\n            optims['discriminator_z'].step()\n            \n            history_per_epoch['gz'].append(gz_loss.item())\n            history_per_epoch['dx'].append(dx_loss.item())\n            history_per_epoch['dz'].append(dz_loss.item())\n            \n    history['gx'].append(np.mean(history_per_epoch['gx']))\n    history['gz'].append(np.mean(history_per_epoch['gz']))\n    history['dx'].append(np.mean(history_per_epoch['dx']))\n    history['dz'].append(np.mean(history_per_epoch['dz']))\n        \n    with torch.set_grad_enabled(False):\n      with out:\n        display.clear_output(wait=True)\n        print(f\"\"\"Epoch: {epoch}/{Epochs}  Discr Loss: {history['dx'][-1]},{history['dz'][-1]}   \n              Gen Loss: {history['gx'][-1]}, {history['gz'][-1]} \\n Monet2Photo \\t\\t\\t\\t Photo2Monet\"\"\")\n        Z_fake = Generator_x.forward(random.choice(Test_monet.dataset)[np.newaxis, :].cuda())\n        X_fake = Generator_z.forward(random.choice(Test_photo.dataset)[np.newaxis, :].cuda())\n        show_grid([Z_fake.view(3,256,256).cpu(), X_fake.view(3,256,256).cpu()], [1, 2])      \n        del Z_fake\n        del X_fake\n    \n","metadata":{"execution":{"iopub.status.busy":"2022-01-30T10:29:07.524317Z","iopub.execute_input":"2022-01-30T10:29:07.524567Z","iopub.status.idle":"2022-01-30T17:59:25.076056Z","shell.execute_reply.started":"2022-01-30T10:29:07.52454Z","shell.execute_reply":"2022-01-30T17:59:25.075013Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Chapter 4 - result's analysis and saving model's parameters\n","metadata":{}},{"cell_type":"code","source":"figure = plt.figure(figsize=(12, 7))\nplt.plot(history['dx'], label='Discriminator_x')\nplt.plot(history['gx'], label='Generator_x')\nplt.plot(history['dz'], label='Discriminator_z')\nplt.plot(history['gz'], label='Generator_z')\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-30T17:59:40.216362Z","iopub.execute_input":"2022-01-30T17:59:40.216885Z","iopub.status.idle":"2022-01-30T17:59:40.528727Z","shell.execute_reply.started":"2022-01-30T17:59:40.216845Z","shell.execute_reply":"2022-01-30T17:59:40.528076Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Pathdx = './CycleGAN++_82_dx'\nPathgx = './CycleGAN++_82_gx'\nPathdz = './CycleGAN++_82_dz'\nPathgz = './CycleGAN++_82_gz'\ntorch.save(Discriminator_x.state_dict(), Pathdx)\ntorch.save(Generator_x.state_dict(), Pathgx)\ntorch.save(Discriminator_z.state_dict(), Pathdz)\ntorch.save(Generator_z.state_dict(), Pathgz)","metadata":{"execution":{"iopub.status.busy":"2022-01-30T17:59:38.135986Z","iopub.execute_input":"2022-01-30T17:59:38.136272Z","iopub.status.idle":"2022-01-30T17:59:38.21597Z","shell.execute_reply.started":"2022-01-30T17:59:38.136221Z","shell.execute_reply":"2022-01-30T17:59:38.21526Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<a href=\"CycleGAN++_75_dx\"> CycleGAN+_75_dx </a>\n\n<a href=\"CycleGAN++_75_dz\"> CycleGAN+_75_dz </a>\n\n<a href=\"CycleGAN++_75_gx\"> CycleGAN+_75_gx </a>\n\n<a href=\"CycleGAN++_75_gz\"> CycleGAN+_75_gz </a>","metadata":{}},{"cell_type":"code","source":"n_samples = 6\nreal = []\nfakes = []\nGenerator_z.eval()\nfor test_photo in Test_photo:\n    with torch.set_grad_enabled(False):\n        real.append(test_photo.view(3, 256, 256))\n        fakes.append(Generator_z.forward(test_photo.cuda()).view(3, 256, 256).cpu())\n    n_samples -=1\n    if n_samples <= 0:\n        break\nshow_grid(real+fakes, [2, 6], 18)            \n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-30T18:03:17.292053Z","iopub.execute_input":"2022-01-30T18:03:17.292338Z","iopub.status.idle":"2022-01-30T18:03:17.924912Z","shell.execute_reply.started":"2022-01-30T18:03:17.292305Z","shell.execute_reply":"2022-01-30T18:03:17.924217Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}